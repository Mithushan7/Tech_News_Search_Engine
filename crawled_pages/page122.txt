URL: https://www.oversightboard.com/meet-the-board/
Title: Oversight Board’s members
OpenAI is launching an ‘independent’ safety board that can stop its model releases - The VergeSkip to main contentThe VergeThe Verge logo.The Verge homepageThe Verge homepageThe VergeThe Verge logo./Tech/Reviews/Science/Entertainment/AI/MoreMenuExpandThe VergeThe Verge logo.MenuExpandOpenAI/Artificial Intelligence/TechOpenAI is launching an ‘independent’ safety board that can stop its model releasesOpenAI is launching an ‘independent’ safety board that can stop its model releases / The company’s Safety and Security Committee will become an ‘independent Board oversight committee.’By  Jay Peters, a news editor who writes about technology, video games, and virtual worlds. He’s submitted several accepted emoji proposals to the Unicode Consortium. Sep 16, 2024, 10:08 PM UTCShare this storyThreads Image: The VergeOpenAI is turning its Safety and Security Committee into an independent “Board oversight committee” that has the authority to delay model launches over safety concerns, according to an OpenAI blog post. The committee made the recommendation to make the independent board after a recent 90-day review of OpenAI’s “safety and security-related processes and safeguards.”The committee, which is chaired by Zico Kolter and includes Adam D’Angelo, Paul Nakasone, and Nicole Seligman, will “be briefed by company leadership on safety evaluations for major model releases, and will, along with the full board, exercise oversight over model launches, including having the authority to delay a release until safety concerns are addressed,” OpenAI says. OpenAI’s full board of directors will also receive “periodic briefings” on “safety and security matters.” The members of OpenAI’s safety committee are also members of the company’s broader board of directors, so it’s unclear exactly how independent the committee actually is or how that independence is structured. (CEO Sam Altman was previously on the committee, but isn’t anymore.) We’ve asked OpenAI for comment. By establishing an independent safety board, it appears OpenAI is taking a somewhat similar approach as Meta’s Oversight Board, which reviews some of Meta’s content policy decisions and can make rulings that Meta has to follow. None of the Oversight Board’s members are on Meta’s board of directors.The review by OpenAI’s Safety and Security Committee also helped “additional opportunities for industry collaboration and information sharing to advance the security of the AI industry.” The company also says it will look for “more ways to share and explain our safety work” and for “more opportunities for independent testing of our systems.” Update, September 16th: Added that Sam Altman is no longer on the committee.CommentsMost PopularMost PopularWhat’s this new mystery Nintendo device?Marvel’s new Thunderbolts trailer is armed to the teethGoogle TV Streamer review: smarter than your average set-top boxX will let people you’ve blocked see your postsArc creator Josh Miller on why you need a better browser than ChromeVerge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content FromMore from Artificial IntelligenceApple gets ready for AI: all the news on iOS 18, macOS Sequoia, and moreMicrosoft’s Office apps are getting more useful Copilot AI featuresCopilot Pages is Microsoft’s new collaborative AI playground for businessesApple confirms the iPhone 16 has 8GB of RAMAdvertiser Content FromThe VergeThe Verge logo.Cookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform StatusHow We Rate and Review ProductsContactTip UsCommunity GuidelinesAboutEthics StatementThe Verge is a vox media networkAdvertise with usJobs @ Vox Media© 2024 Vox Media, LLC. All Rights Reserved